{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.loadtxt('train.csv', delimiter=',', skiprows=1)\n",
    "test = np.loadtxt('test.csv', delimiter=',', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# сохраняем разметку в отдельную переменную\n",
    "train_label = train[:, 0]\n",
    "# приводим размерность к удобному для обаботки виду\n",
    "train_img = train[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_img, train_label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1000, input_dim=784, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(10, kernel_initializer='normal', activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"SGD\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 795,010\n",
      "Trainable params: 795,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "33600/33600 [==============================] - 3s - loss: 1.3678 - acc: 0.6808     \n",
      "Epoch 2/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.7391 - acc: 0.8353     \n",
      "Epoch 3/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.5710 - acc: 0.8625     \n",
      "Epoch 4/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.4911 - acc: 0.8763     \n",
      "Epoch 5/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.4433 - acc: 0.8858     \n",
      "Epoch 6/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.4108 - acc: 0.8917     \n",
      "Epoch 7/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.3869 - acc: 0.8970     \n",
      "Epoch 8/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.3683 - acc: 0.9009     \n",
      "Epoch 9/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.3533 - acc: 0.9031     \n",
      "Epoch 10/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.3408 - acc: 0.9060     \n",
      "Epoch 11/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.3301 - acc: 0.9093     \n",
      "Epoch 12/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.3207 - acc: 0.9111     \n",
      "Epoch 13/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.3126 - acc: 0.9140     \n",
      "Epoch 14/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.3053 - acc: 0.9158     \n",
      "Epoch 15/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2985 - acc: 0.9176     \n",
      "Epoch 16/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.2923 - acc: 0.9191     \n",
      "Epoch 17/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.2868 - acc: 0.9206     \n",
      "Epoch 18/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.2816 - acc: 0.9219     \n",
      "Epoch 19/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.2766 - acc: 0.9227     \n",
      "Epoch 20/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2721 - acc: 0.9246     \n",
      "Epoch 21/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.2678 - acc: 0.9257     \n",
      "Epoch 22/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2637 - acc: 0.9270     \n",
      "Epoch 23/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2598 - acc: 0.9280     \n",
      "Epoch 24/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2561 - acc: 0.9300     \n",
      "Epoch 25/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2525 - acc: 0.9302     \n",
      "Epoch 26/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2492 - acc: 0.9316     \n",
      "Epoch 27/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2458 - acc: 0.9326     \n",
      "Epoch 28/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2428 - acc: 0.9331     \n",
      "Epoch 29/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2397 - acc: 0.9347     \n",
      "Epoch 30/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2368 - acc: 0.9354     \n",
      "Epoch 31/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2340 - acc: 0.9364     \n",
      "Epoch 32/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2312 - acc: 0.9364     \n",
      "Epoch 33/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2285 - acc: 0.9374     \n",
      "Epoch 34/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2258 - acc: 0.9379     \n",
      "Epoch 35/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2233 - acc: 0.9384     \n",
      "Epoch 36/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2209 - acc: 0.9391     \n",
      "Epoch 37/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2185 - acc: 0.9398     \n",
      "Epoch 38/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2160 - acc: 0.9401     \n",
      "Epoch 39/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2138 - acc: 0.9410     \n",
      "Epoch 40/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2116 - acc: 0.9413     \n",
      "Epoch 41/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2094 - acc: 0.9420     \n",
      "Epoch 42/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2072 - acc: 0.9426     \n",
      "Epoch 43/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2050 - acc: 0.9436     \n",
      "Epoch 44/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2031 - acc: 0.9436     \n",
      "Epoch 45/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.2010 - acc: 0.9442     \n",
      "Epoch 46/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1992 - acc: 0.9449     \n",
      "Epoch 47/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1972 - acc: 0.9456     \n",
      "Epoch 48/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1953 - acc: 0.9460     \n",
      "Epoch 49/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1934 - acc: 0.9469     \n",
      "Epoch 50/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1917 - acc: 0.9469     \n",
      "Epoch 51/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1899 - acc: 0.9476     \n",
      "Epoch 52/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1881 - acc: 0.9479     \n",
      "Epoch 53/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1863 - acc: 0.9485     \n",
      "Epoch 54/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1846 - acc: 0.9493     \n",
      "Epoch 55/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1830 - acc: 0.9498     \n",
      "Epoch 56/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1813 - acc: 0.9498     \n",
      "Epoch 57/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1796 - acc: 0.9506     \n",
      "Epoch 58/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1781 - acc: 0.9511     \n",
      "Epoch 59/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1766 - acc: 0.9516     \n",
      "Epoch 60/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1751 - acc: 0.9517     \n",
      "Epoch 61/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1736 - acc: 0.9524     \n",
      "Epoch 62/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1721 - acc: 0.9531     \n",
      "Epoch 63/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1706 - acc: 0.9536     \n",
      "Epoch 64/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1692 - acc: 0.9538     \n",
      "Epoch 65/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1677 - acc: 0.9545     \n",
      "Epoch 66/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1664 - acc: 0.9548     \n",
      "Epoch 67/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1650 - acc: 0.9554     \n",
      "Epoch 68/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1637 - acc: 0.9555     \n",
      "Epoch 69/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1624 - acc: 0.9560     \n",
      "Epoch 70/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1609 - acc: 0.9563     \n",
      "Epoch 71/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1598 - acc: 0.9569     \n",
      "Epoch 72/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1584 - acc: 0.9574     \n",
      "Epoch 73/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1572 - acc: 0.9578     \n",
      "Epoch 74/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1559 - acc: 0.9580     \n",
      "Epoch 75/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1547 - acc: 0.9584     \n",
      "Epoch 76/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1535 - acc: 0.9586     \n",
      "Epoch 77/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1523 - acc: 0.9595     \n",
      "Epoch 78/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1512 - acc: 0.9593     \n",
      "Epoch 79/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1500 - acc: 0.9596     \n",
      "Epoch 80/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1488 - acc: 0.9595     \n",
      "Epoch 81/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1477 - acc: 0.9604     \n",
      "Epoch 82/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1466 - acc: 0.9608     \n",
      "Epoch 83/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1455 - acc: 0.9607     \n",
      "Epoch 84/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1444 - acc: 0.9610     \n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 3s - loss: 0.1433 - acc: 0.9613     \n",
      "Epoch 86/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.1423 - acc: 0.9619     \n",
      "Epoch 87/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.1412 - acc: 0.9618     \n",
      "Epoch 88/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.1403 - acc: 0.9621     \n",
      "Epoch 89/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.1392 - acc: 0.9626     \n",
      "Epoch 90/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.1382 - acc: 0.9628     \n",
      "Epoch 91/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.1372 - acc: 0.9632     \n",
      "Epoch 92/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.1362 - acc: 0.9634     \n",
      "Epoch 93/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.1352 - acc: 0.9636     \n",
      "Epoch 94/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1343 - acc: 0.9638     \n",
      "Epoch 95/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1334 - acc: 0.9641     \n",
      "Epoch 96/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.1324 - acc: 0.9643     \n",
      "Epoch 97/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.1315 - acc: 0.9646     \n",
      "Epoch 98/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1306 - acc: 0.9648     \n",
      "Epoch 99/100\n",
      "33600/33600 [==============================] - 3s - loss: 0.1297 - acc: 0.9652     \n",
      "Epoch 100/100\n",
      "33600/33600 [==============================] - 4s - loss: 0.1288 - acc: 0.9655     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa2f7781cc0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, batch_size=200,epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8224/8400 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95523809523809522"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = np_utils.to_categorical(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_img = train_img.astype('float32')\n",
    "train_img /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(1000, input_dim=784, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(10, kernel_initializer='normal', activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"SGD\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 795,010\n",
      "Trainable params: 795,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.9641 - acc: 0.7800     \n",
      "Epoch 2/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.4768 - acc: 0.8831     \n",
      "Epoch 3/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.3901 - acc: 0.8984     \n",
      "Epoch 4/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.3483 - acc: 0.9063     \n",
      "Epoch 5/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.3217 - acc: 0.9117     \n",
      "Epoch 6/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.3022 - acc: 0.9172     \n",
      "Epoch 7/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.2874 - acc: 0.9208     \n",
      "Epoch 8/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.2747 - acc: 0.9245     \n",
      "Epoch 9/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.2640 - acc: 0.9276     \n",
      "Epoch 10/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.2544 - acc: 0.9302     \n",
      "Epoch 11/200\n",
      "42000/42000 [==============================] - 7s - loss: 0.2461 - acc: 0.9323     \n",
      "Epoch 12/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.2384 - acc: 0.9344     \n",
      "Epoch 13/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.2315 - acc: 0.9365     \n",
      "Epoch 14/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.2248 - acc: 0.9382     \n",
      "Epoch 15/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.2186 - acc: 0.9403     \n",
      "Epoch 16/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.2129 - acc: 0.9415     \n",
      "Epoch 17/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.2077 - acc: 0.9431     \n",
      "Epoch 18/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.2025 - acc: 0.9441     \n",
      "Epoch 19/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1978 - acc: 0.9456     \n",
      "Epoch 20/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1933 - acc: 0.9469     \n",
      "Epoch 21/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1888 - acc: 0.9481     \n",
      "Epoch 22/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1847 - acc: 0.9491     \n",
      "Epoch 23/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1807 - acc: 0.9503     \n",
      "Epoch 24/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1769 - acc: 0.9514     \n",
      "Epoch 25/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1732 - acc: 0.9523     \n",
      "Epoch 26/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1696 - acc: 0.9537     \n",
      "Epoch 27/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1663 - acc: 0.9546     \n",
      "Epoch 28/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1632 - acc: 0.9560     \n",
      "Epoch 29/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1599 - acc: 0.9565     \n",
      "Epoch 30/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1570 - acc: 0.9574     \n",
      "Epoch 31/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1540 - acc: 0.9583     \n",
      "Epoch 32/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1511 - acc: 0.9594     \n",
      "Epoch 33/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1485 - acc: 0.9601     \n",
      "Epoch 34/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1458 - acc: 0.9610     \n",
      "Epoch 35/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1433 - acc: 0.9618     \n",
      "Epoch 36/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1408 - acc: 0.9624     \n",
      "Epoch 37/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1384 - acc: 0.9631     \n",
      "Epoch 38/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1361 - acc: 0.9638     \n",
      "Epoch 39/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1339 - acc: 0.9649     \n",
      "Epoch 40/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1318 - acc: 0.9653     \n",
      "Epoch 41/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1296 - acc: 0.9659     \n",
      "Epoch 42/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1276 - acc: 0.9668     \n",
      "Epoch 43/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1256 - acc: 0.9672     \n",
      "Epoch 44/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1237 - acc: 0.9682     \n",
      "Epoch 45/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1218 - acc: 0.9683     \n",
      "Epoch 46/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1199 - acc: 0.9690     \n",
      "Epoch 47/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1182 - acc: 0.9693     \n",
      "Epoch 48/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1164 - acc: 0.9700     \n",
      "Epoch 49/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1148 - acc: 0.9699     \n",
      "Epoch 50/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1131 - acc: 0.9707     \n",
      "Epoch 51/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1116 - acc: 0.9713     \n",
      "Epoch 52/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1100 - acc: 0.9715     \n",
      "Epoch 53/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1084 - acc: 0.9720     \n",
      "Epoch 54/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1070 - acc: 0.9721     \n",
      "Epoch 55/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1055 - acc: 0.9728     \n",
      "Epoch 56/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1041 - acc: 0.9732     \n",
      "Epoch 57/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1027 - acc: 0.9735     \n",
      "Epoch 58/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1014 - acc: 0.9735     \n",
      "Epoch 59/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.1001 - acc: 0.9741     \n",
      "Epoch 60/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0988 - acc: 0.9746     \n",
      "Epoch 61/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0975 - acc: 0.9745     \n",
      "Epoch 62/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0963 - acc: 0.9751     \n",
      "Epoch 63/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0951 - acc: 0.9753     \n",
      "Epoch 64/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0939 - acc: 0.9756     \n",
      "Epoch 65/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0927 - acc: 0.9763     \n",
      "Epoch 66/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0916 - acc: 0.9762     \n",
      "Epoch 67/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0905 - acc: 0.9765     \n",
      "Epoch 68/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0894 - acc: 0.9771     \n",
      "Epoch 69/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0884 - acc: 0.9773     \n",
      "Epoch 70/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0873 - acc: 0.9776     \n",
      "Epoch 71/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0863 - acc: 0.9780     \n",
      "Epoch 72/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0853 - acc: 0.9781     \n",
      "Epoch 73/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0842 - acc: 0.9784     \n",
      "Epoch 74/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0833 - acc: 0.9787     \n",
      "Epoch 75/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0824 - acc: 0.9785     \n",
      "Epoch 76/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0814 - acc: 0.9792     \n",
      "Epoch 77/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0805 - acc: 0.9792     \n",
      "Epoch 78/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0796 - acc: 0.9796     \n",
      "Epoch 79/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0787 - acc: 0.9799     \n",
      "Epoch 80/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0779 - acc: 0.9801     \n",
      "Epoch 81/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0771 - acc: 0.9806     \n",
      "Epoch 82/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0762 - acc: 0.9809     \n",
      "Epoch 83/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0754 - acc: 0.9811     \n",
      "Epoch 84/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0746 - acc: 0.9814     \n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000/42000 [==============================] - 6s - loss: 0.0738 - acc: 0.9815     \n",
      "Epoch 86/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0730 - acc: 0.9817     \n",
      "Epoch 87/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0722 - acc: 0.9817     \n",
      "Epoch 88/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0715 - acc: 0.9824     \n",
      "Epoch 89/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0707 - acc: 0.9824     \n",
      "Epoch 90/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0700 - acc: 0.9827     \n",
      "Epoch 91/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0693 - acc: 0.9829     \n",
      "Epoch 92/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0686 - acc: 0.9832     \n",
      "Epoch 93/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0678 - acc: 0.9834     \n",
      "Epoch 94/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0672 - acc: 0.9837     \n",
      "Epoch 95/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0665 - acc: 0.9838     \n",
      "Epoch 96/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0658 - acc: 0.9840     \n",
      "Epoch 97/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0652 - acc: 0.9841     \n",
      "Epoch 98/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0645 - acc: 0.9845     \n",
      "Epoch 99/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0639 - acc: 0.9846     \n",
      "Epoch 100/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0633 - acc: 0.9849     \n",
      "Epoch 101/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0627 - acc: 0.9848     \n",
      "Epoch 102/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0620 - acc: 0.9852     \n",
      "Epoch 103/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0614 - acc: 0.9855     \n",
      "Epoch 104/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0608 - acc: 0.9855     \n",
      "Epoch 105/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0603 - acc: 0.9857     \n",
      "Epoch 106/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0597 - acc: 0.9860     \n",
      "Epoch 107/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0592 - acc: 0.9862     \n",
      "Epoch 108/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0585 - acc: 0.9864     \n",
      "Epoch 109/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0580 - acc: 0.9864     \n",
      "Epoch 110/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0575 - acc: 0.9863     \n",
      "Epoch 111/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0569 - acc: 0.9867     \n",
      "Epoch 112/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0564 - acc: 0.9867     \n",
      "Epoch 113/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0559 - acc: 0.9872     \n",
      "Epoch 114/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0554 - acc: 0.9872     \n",
      "Epoch 115/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0549 - acc: 0.9873     \n",
      "Epoch 116/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0544 - acc: 0.9872     \n",
      "Epoch 117/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0539 - acc: 0.9875     \n",
      "Epoch 118/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0534 - acc: 0.9876     \n",
      "Epoch 119/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0529 - acc: 0.9875     \n",
      "Epoch 120/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0525 - acc: 0.9881     \n",
      "Epoch 121/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0520 - acc: 0.9880     \n",
      "Epoch 122/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0515 - acc: 0.9881     \n",
      "Epoch 123/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0511 - acc: 0.9884     \n",
      "Epoch 124/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0506 - acc: 0.9884     \n",
      "Epoch 125/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0502 - acc: 0.9886     \n",
      "Epoch 126/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0498 - acc: 0.9889     \n",
      "Epoch 127/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0492 - acc: 0.9888     \n",
      "Epoch 128/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0489 - acc: 0.9888     \n",
      "Epoch 129/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0484 - acc: 0.9891     \n",
      "Epoch 130/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0480 - acc: 0.9891     \n",
      "Epoch 131/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0476 - acc: 0.9892     \n",
      "Epoch 132/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0473 - acc: 0.9893     \n",
      "Epoch 133/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0469 - acc: 0.9894     \n",
      "Epoch 134/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0464 - acc: 0.9898     \n",
      "Epoch 135/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0461 - acc: 0.9897     \n",
      "Epoch 136/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0457 - acc: 0.9899     \n",
      "Epoch 137/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0453 - acc: 0.9900     \n",
      "Epoch 138/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0449 - acc: 0.9899     \n",
      "Epoch 139/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0446 - acc: 0.9903     \n",
      "Epoch 140/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0442 - acc: 0.9905     \n",
      "Epoch 141/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0438 - acc: 0.9905     \n",
      "Epoch 142/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0434 - acc: 0.9907     \n",
      "Epoch 143/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0431 - acc: 0.9907     \n",
      "Epoch 144/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0427 - acc: 0.9907     \n",
      "Epoch 145/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0424 - acc: 0.9911     \n",
      "Epoch 146/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0421 - acc: 0.9910     \n",
      "Epoch 147/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0417 - acc: 0.9912     \n",
      "Epoch 148/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0414 - acc: 0.9911     \n",
      "Epoch 149/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0411 - acc: 0.9913     \n",
      "Epoch 150/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0407 - acc: 0.9915     \n",
      "Epoch 151/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0404 - acc: 0.9916     \n",
      "Epoch 152/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0401 - acc: 0.9918     \n",
      "Epoch 153/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0398 - acc: 0.9918     \n",
      "Epoch 154/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0395 - acc: 0.9919     \n",
      "Epoch 155/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0392 - acc: 0.9920     \n",
      "Epoch 156/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0389 - acc: 0.9921     \n",
      "Epoch 157/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0386 - acc: 0.9921     \n",
      "Epoch 158/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0383 - acc: 0.9923     \n",
      "Epoch 159/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0380 - acc: 0.9924     \n",
      "Epoch 160/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0377 - acc: 0.9926     \n",
      "Epoch 161/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0374 - acc: 0.9926     \n",
      "Epoch 162/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0371 - acc: 0.9927     \n",
      "Epoch 163/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0368 - acc: 0.9928     \n",
      "Epoch 164/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0365 - acc: 0.9928     \n",
      "Epoch 165/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0363 - acc: 0.9928     \n",
      "Epoch 166/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0360 - acc: 0.9931     \n",
      "Epoch 167/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0357 - acc: 0.9932     \n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000/42000 [==============================] - 6s - loss: 0.0355 - acc: 0.9931     \n",
      "Epoch 169/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0352 - acc: 0.9934     \n",
      "Epoch 170/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0349 - acc: 0.9934     \n",
      "Epoch 171/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0346 - acc: 0.9934     \n",
      "Epoch 172/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0344 - acc: 0.9935     \n",
      "Epoch 173/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0341 - acc: 0.9936     \n",
      "Epoch 174/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0339 - acc: 0.9938     \n",
      "Epoch 175/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0336 - acc: 0.9938     \n",
      "Epoch 176/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0334 - acc: 0.9939     \n",
      "Epoch 177/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0332 - acc: 0.9940     \n",
      "Epoch 178/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0330 - acc: 0.9940     \n",
      "Epoch 179/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0327 - acc: 0.9941     \n",
      "Epoch 180/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0325 - acc: 0.9941     \n",
      "Epoch 181/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0322 - acc: 0.9943     \n",
      "Epoch 182/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0320 - acc: 0.9944     \n",
      "Epoch 183/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0318 - acc: 0.9945     \n",
      "Epoch 184/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0315 - acc: 0.9945     \n",
      "Epoch 185/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0313 - acc: 0.9945     \n",
      "Epoch 186/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0311 - acc: 0.9949     \n",
      "Epoch 187/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0309 - acc: 0.9946     \n",
      "Epoch 188/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0307 - acc: 0.9948     \n",
      "Epoch 189/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0305 - acc: 0.9948     \n",
      "Epoch 190/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0302 - acc: 0.9947     \n",
      "Epoch 191/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0300 - acc: 0.9948     \n",
      "Epoch 192/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0298 - acc: 0.9950     \n",
      "Epoch 193/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0296 - acc: 0.9952     \n",
      "Epoch 194/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0294 - acc: 0.9951     \n",
      "Epoch 195/200\n",
      "42000/42000 [==============================] - 7s - loss: 0.0292 - acc: 0.9952     \n",
      "Epoch 196/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0290 - acc: 0.9951     \n",
      "Epoch 197/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0288 - acc: 0.9953     \n",
      "Epoch 198/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0286 - acc: 0.9955     \n",
      "Epoch 199/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0284 - acc: 0.9955     \n",
      "Epoch 200/200\n",
      "42000/42000 [==============================] - 6s - loss: 0.0282 - acc: 0.9954     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa2f676d470>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_img,Y, batch_size=100,epochs=200,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.astype('float32')\n",
    "test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27968/28000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm submit.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submit.txt', 'w') as dst:\n",
    "    dst.write('ImageId,Label\\n')\n",
    "    for i, p in enumerate(predictions, 1):\n",
    "        dst.write('%s,%s\\n' % (i, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3sAAACZCAIAAAAZy7SgAAAAA3NCSVQICAjb4U/gAAAAGXRFWHRT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\nXP/urWdhpW8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='Screenshot from 2017-09-24 08-12-08.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
